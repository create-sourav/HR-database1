# -*- coding: utf-8 -*-
"""HR database EDA and ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rK_m3SQ2o8w4PC1Kqc7NprOoEjubDB5O
"""

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

from google.colab import files
uploaded=files.upload()

df=pd.read_csv("HR database1.csv")
df.head(5)

df.shape   ## total rows and columns of the dataset

df.info()    ## information related to the columns
df.isnull().sum().sum()  ## no null values present

df.duplicated().sum()    ### No duplicates

"""## Outliers checking"""

sns.boxplot(x=df["MonthlyIncome"])
plt.show()                                   ### outleirs can be seen in boxlot

"""## Outliers cliping"""

for column in df.select_dtypes(include="number").columns:

    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    lower_limit = Q1 - 1.5 * IQR
    upper_limit = Q3 + 1.5 * IQR

    # Cap values within limits
    df[column] = df[column].clip(lower_limit, upper_limit)

sns.boxplot(x=df["MonthlyIncome"])
plt.show()                                    ### Outliers has been cliped.

"""## Top 10 job role and job level that are showed highest attrition.  """

df[df["Attrition"] == "Yes"][["JobLevel", "JobRole"]][:10]
### Joblevel 1,2, 3 which are Sales Executive, Laboraory Technician, etc.

"""## MontlyIncome plays a role in Job level and role based attrition  """

df.groupby([ "JobLevel", "JobRole", "Attrition"])["MonthlyIncome"].sum().sort_values(ascending=True)
### MonthlyIncome does plays a role in in Attrition.

"""## Attrition rate"""

print(((df["Attrition"]=="Yes").sum() /len(df["Attrition"])*100))   # Attrition_rate = 16.12%


# df.head(2)

df.shape

"""### Exploratory Analysis Dashborad"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")
fig, axes = plt.subplots(2, 3, figsize=(16, 10))

# Education vs Attrition (percent within each Education)
sns.countplot(x="Education", hue="Attrition", data=df, stat="percent", ax=axes[0, 0], palette="crest")
axes[0, 0].set_title("Attrition by Education")
axes[0, 0].set_xlabel("Education Level")
axes[0, 0].set_ylabel("Percentage (%)")

# 2) Years Since Last Promotion vs Attrition (percent within each group)
sns.countplot(x="YearsSinceLastPromotion", hue="Attrition", data=df, stat="percent", ax=axes[0, 1], palette="viridis")
axes[0, 1].set_title("Attrition by Years Since Last Promotion")
axes[0, 1].set_xlabel("Years Since Last Promotion")
axes[0, 1].set_ylabel("")

# Job Level vs Attrition (percent)
sns.countplot(x="JobLevel", hue="Attrition", data=df, stat="percent", ax=axes[0, 2], palette="mako")
axes[0, 2].set_title("Attrition by Job Level")
axes[0, 2].set_xlabel("Job Level")
axes[0, 2].set_ylabel("")

# Age distribution by Attrition
sns.histplot(x="Age", hue="Attrition", data=df, bins=15, stat="percent", kde=True, ax=axes[1, 0], palette="viridis")
axes[1, 0].set_title("Age Distribution by Attrition")
axes[1, 0].set_xlabel("Age")
axes[1, 0].set_ylabel("Percentage(%)")

# Department vs Attrition (percent)
sns.countplot(x="Department", hue="Attrition", data=df, stat="percent", ax=axes[1, 1], palette="rocket")
axes[1, 1].set_title("Attrition by Department")
axes[1, 1].set_xlabel("Department")
axes[1, 1].set_ylabel("")
axes[1, 1].tick_params(axis='x', rotation=30)

# Monthly Income distribution by Attrition (histogram)
sns.histplot(x="MonthlyIncome", hue="Attrition", data=df,stat="percent", bins=10, kde=True, ax=axes[1, 2], palette="viridis")
axes[1, 2].set_title("Monthly Income by Attrition")
axes[1, 2].set_xlabel("Monthly Income")
axes[1, 2].set_ylabel("")

plt.tight_layout()
plt.show()

"""# üìä Employee Attrition ‚Äî Exploratory Data Analysis (EDA)

## üß† Objective
The goal of this analysis is to explore factors that contribute to **employee attrition** ‚Äî i.e., employees who leave the company (`Attrition = Yes`).  
We analyze variables like **Education**, **Years Since Last Promotion**, **Job Level**, **Age**, **Department**, and **Monthly Income** to understand key churn drivers.

---

## üßæ Dataset Overview

| Feature | Description |
|----------|--------------|
| `Attrition` | Whether an employee left (`Yes`) or stayed (`No`) |
| `Education` | Education level (1 = Below College to 5 = Doctorate) |
| `YearsSinceLastPromotion` | Years since last promotion |
| `JobLevel` | Job seniority (1 ‚Äì 5) |
| `Age` | Employee age |
| `Department` | Department name |
| `MonthlyIncome` | Monthly salary (USD) |

---

## üìà Exploratory Insights

### 1Ô∏è‚É£ Attrition by Education
- Most employees are at **Education Level 3 (Bachelor‚Äôs)**, which also shows the **highest attrition**.  
- Employees with advanced degrees (Master‚Äôs/Doctorate) tend to stay longer.



---

### 2Ô∏è‚É£ Attrition by Years Since Last Promotion
- Highest attrition occurs among employees with **0‚Äì1 years since promotion**, suggesting **career stagnation** drives churn.  
- Attrition decreases with increasing promotion intervals.



---

### 3Ô∏è‚É£ Attrition by Job Level
- **Job Levels 1‚Äì2** have higher attrition rates.  
- **Senior employees (Levels 4‚Äì5)** show strong retention.



---

### 4Ô∏è‚É£ Age Distribution by Attrition
- Younger employees (**25‚Äì35 years**) have the highest attrition.  
- Older employees (**40+**) tend to remain longer in the organization.



---

### 5Ô∏è‚É£ Attrition by Department
- **Research & Development** has the **largest workforce and highest attrition count**.  
- **Sales** also shows notable churn; **HR** remains low.



---

### 6Ô∏è‚É£ Attrition by Monthly Income
- Attrition is **highest among low-income employees (< $5,000/month)**.  
- Attrition declines as income increases ‚Äî pay strongly influences retention.



---

## üß© Key Takeaways
‚úÖ Younger, low-income, and junior-level employees are more likely to leave.  
‚úÖ Recent lack of promotions is a major attrition factor.  
‚úÖ Higher education and senior roles correlate with lower attrition.  
‚úÖ Retention efforts should target **early-career and low-income** groups.

# Machine learning and predictive analysis
"""

df.info()

# preprosseing
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import BorderlineSMOTE





# Define Target and Features
y = df["Attrition"]  # Target column
X = df.drop(["Attrition","EmployeeNumber","EmployeeCount"], axis=1) # Feature columns



# Encode Categorical Variables (1/0)
X = pd.get_dummies(X, drop_first=True, dtype=int)


# Encode Target Variable (Yes/No -> 1/0)
encoders = {}
if y.dtype == "object" or str(y.dtype).startswith("category"):
    label = LabelEncoder()
    y = label.fit_transform(y.astype(str))
    encoders["Attrition"] = label


# Train-Test Split
x_train, x_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=0
)

# Feature Scaling
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)


# Handle Class Imbalance (BorderlineSMOTE)
sm = BorderlineSMOTE(random_state=0, kind="borderline-1")
x_train_resample, y_train_resample = sm.fit_resample(x_train_scaled, y_train)


# Check Class Balance
print("Before SMOTE:\n", pd.Series(y_train).value_counts())
print("\nAfter SMOTE:\n", pd.Series(y_train_resample).value_counts())

print("\nEncoded Target (y):")
print(y)

print("\nEncoded Feature DataFrame (X):")
display(X.head())

"""### Model selection"""

# Models and evaluation

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import *

models = {
    "Random Forest": RandomForestClassifier(class_weight="balanced", random_state=42),
    "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Naive Bayes": GaussianNB(),
}

for name, model in models.items():
    print("\n===", name, "===")

    model.fit(x_train_resample, y_train_resample)

    # Predictions
    y_prediction = model.predict(x_test_scaled)

    # Probability for ROC AUC (class 1)
    y_prob = model.predict_proba(x_test_scaled)[:, 1]

    # Metrics
    acc = accuracy_score(y_test, y_prediction)
    recall = recall_score(y_test, y_prediction)   # Recall for attrition class (1)
    f1 = f1_score(y_test, y_prediction, average="weighted")
    roc_auc = roc_auc_score(y_test, y_prob)
    confusion = confusion_matrix(y_test, y_prediction)
    report = classification_report(y_test, y_prediction, zero_division=0)

    # Print output
    print("Accuracy:", acc)
    print("ROC AUC:", roc_auc)
    print("Recall (Attrition=Yes):", recall)
    print("F1-score (weighted):", f1)
    print("Confusion Matrix:\n", confusion)
    print("Classification Report:\n", report)

"""### Model tuning"""

from sklearn.metrics import roc_auc_score, recall_score, f1_score

RandomForest_tuned = RandomForestClassifier(
    n_estimators=300,
    max_depth=15,
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight="balanced",
    random_state=42
)

# Train
RandomForest_tuned.fit(x_train_resample, y_train_resample)

# Train & Test accuracy
print("Train accuracy:", RandomForest_tuned.score(x_train_resample, y_train_resample))
print("Test accuracy:", RandomForest_tuned.score(x_test_scaled, y_test))

# Predictions
y_prediction = RandomForest_tuned.predict(x_test_scaled)

# Probabilities
y_probability = RandomForest_tuned.predict_proba(x_test_scaled)[:, 1]

# ROC AUC
roc_auc = roc_auc_score(y_test, y_probability)
print("ROC AUC:", roc_auc)

# Recall for positive class (Attrition = Yes)
recall = recall_score(y_test, y_prediction)
print("Recall:", recall)

# Weighted F1 (balanced across classes)
f1 = f1_score(y_test, y_prediction, average="weighted")
print("F1 score:", f1)

"""### Optimal Attrition Probability Threshold"""

from sklearn.metrics import roc_curve

# Compute ROC
fpr, tpr, thresholds = roc_curve(y_test, RandomForest_tuned.predict_proba(x_test_scaled)[:, 1])  #False Positive Rate (fpr), True Positive Rate (tpr)

# Find optimal threshold (Youden's J)
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]

print(f"Optimal Attrition Probability Threshold: {optimal_threshold:.3f}")

"""## Recall improvement using optimal_thresold"""

y_pred_adjusted = (y_probability >= optimal_threshold).astype(int)
recall_adj = recall_score(y_test, y_pred_adjusted)
print(recall_adj)

# y_pred_adjusted uses the optimal threshold to improve detection of churners.
# recall_adj tells how many actual 'Yes' attrition cases the model correctly identifies
# after threshold tuning (higher recall = better for HR use-cases).

""" ###  Top 10 Most Important Features Influencing Attrition

"""

importances = pd.Series(RandomForest_tuned.feature_importances_, index=X.columns)
top10 = importances.sort_values(ascending=False).head(10).reset_index()
top10.columns = ["Feature", "Importance"]


# Seaborn barplot
plt.figure(figsize=(10,6))
sns.barplot(
    data=top10,
    y="Feature",
    x="Importance",
    palette="viridis",
    edgecolor="black"
)


# Add chart titles and labels
plt.title(" Top 10 Most Important Features Influencing Attrition", fontsize=14, fontweight="bold", pad=15)
plt.xlabel("Feature Importance Score", fontsize=12)
plt.ylabel("")
plt.grid(axis="x", linestyle="--", alpha=0.4)
sns.despine(left=True, bottom=True)
plt.tight_layout()
plt.show()

"""**Why EDA Feature Importance Differs from Random Forest Feature Importance?**




 EDA is univariate in nature and Random Forest is a complete Multivariate.

Random Forest evaluates all features simultaneously, capturing:
feature interactions which are non-linear relationships multicollinearity, redundant variables.
This often leads to a different set of ‚Äúimportant‚Äù features than those seen in EDA.


----


Multicollinearity affetcs the data features in the dataset.  
For example:
MonthlyIncome, TotalWorkingYears, YearsAtCompany, Age
When features convey similar information, the Random Forest model distributes predictive power across them, causing each one to appear less important.


--------



Dummy Encoding Spreads Importance
Categorical variables (e.g., Department, JobRole, MaritalStatus) become several one-hot‚Äìencoded features.
Their importance gets distributed across multiple dummy columns, unlike EDA where the categories are viewed together.

### ROC Curve
"""

import matplotlib.pyplot as plt

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, label='ROC Curve')
plt.plot([0,1], [0,1], linestyle='--', color='gray')
plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', label=f'Optimal Threshold = {optimal_threshold:.2f}')
plt.title("ROC Curve ‚Äî Attrition Model")
plt.xlabel("False Positive Rate (1 - Specificity)")
plt.ylabel("True Positive Rate (Sensitivity)")
plt.legend()
plt.show()

"""### Decision Boundary"""

# Scale the entire dataset
X_scaled = scaler.transform(X)

# Predict class and probability
y_pred = RandomForest_tuned.predict(X_scaled)

# Extract class names (from LabelEncoder)
classes = encoders["Attrition"].classes_

# Find the index of "Yes" (Attrition = 1)
Attrition_idx = np.where(classes == "Yes")[0][0]

# Get predicted probability for Attrition = "Yes"
attrition_prob = RandomForest_tuned.predict_proba(X_scaled)[:, Attrition_idx]

# --- Add predictions back to DataFrame ---
df["Predicted_Attrition"] = encoders["Attrition"].inverse_transform(y_pred)
df["Attrition_Probability"] = attrition_prob

plt.figure(figsize=(8,5))
sns.kdeplot(data=df, x="Attrition_Probability", hue="Attrition", fill=True, alpha=0.4)
plt.axvline(optimal_threshold, color='red', linestyle='--', linewidth=2)
plt.title("Attrition Probability Distribution by Actual Status", fontsize=12, fontweight='bold')
plt.xlabel("Attrition Probability"); plt.ylabel("Density")

plt.legend(
    ["Attrition = No (Stayed)",
    "Attrition = Yes (Left)",
    f"Threshold = {optimal_threshold:.2f}"
], loc="upper right")

plt.show()

"""## Actual vs predicted results"""

df["Predicted_Attrition_Adjusted"] = np.where(
    df["Attrition_Probability"] >= optimal_threshold, "Yes", "No"
)

df[["EmployeeNumber", "Attrition", "Predicted_Attrition_Adjusted", "Attrition_Probability"]].head(15)

"""### New Employee Record to predict"""

import pandas as pd

new_employee = pd.DataFrame([{
    "Age": 28,
    "BusinessTravel": "Travel_Rarely",
    "DailyRate": 1100,
    "Department": "Sales",
    "DistanceFromHome": 5,
    "Education": 3,
    "EducationField": "Marketing",
    "EmployeeCount": 1,
    "EmployeeNumber": 9999,              # new employee ID
    "EnvironmentSatisfaction": 3,
    "Gender": "Male",
    "HourlyRate": 70,
    "JobInvolvement": 3,
    "JobLevel": 2,
    "JobRole": "Sales Executive",
    "JobSatisfaction": 3,
    "MaritalStatus": "Single",
    "MonthlyIncome": 4500,
    "MonthlyRate": 15000,
    "NumCompaniesWorked": 2,
    "Over18": "Y",
    "OverTime": "Yes",                  # this employee works overtime
    "PercentSalaryHike": 13,
    "PerformanceRating": 3,
    "RelationshipSatisfaction": 3,
    "StandardHours": 80,
    "StockOptionLevel": 1,
    "TotalWorkingYears": 6,
    "TrainingTimesLastYear": 3,
    "WorkLifeBalance": 2,
    "YearsAtCompany": 3,
    "YearsInCurrentRole": 2,
    "YearsSinceLastPromotion": 1,
    "YearsWithCurrManager": 2
}])

"""### Match Columns to the Model‚Äôs Input and predict the outcome"""

import pandas as pd
import numpy as np

# Columns dropped during training
cols_to_drop = ["EmployeeNumber", "EmployeeCount"]

X_new = new_employee.copy()

# 1. Remove same columns as training
for c in cols_to_drop:
    if c in X_new.columns:
        X_new = X_new.drop(columns=c)

# 2. One-hot encode
X_new = pd.get_dummies(X_new, drop_first=True)

# 3. Align with training columns
X_new = X_new.reindex(columns=X.columns, fill_value=0)

# 4. Scale
X_new_scaled = scaler.transform(X_new)

# 5. Predict class and probability
pred_class = RandomForest_tuned.predict(X_new_scaled)[0]
yes_index = list(encoders["Attrition"].classes_).index("Yes")
pred_prob = RandomForest_tuned.predict_proba(X_new_scaled)[0][yes_index]

# 6. Decode predicted label
predicted_label = encoders["Attrition"].inverse_transform([pred_class])[0]

print("Predicted Attrition:", predicted_label)
print(f"Attrition Probability: {pred_prob:.2%}")

"""# ü§ñ Employee Attrition Prediction ‚Äî Machine Learning Report

## üß† Project Objective
The goal of this machine learning project is to **predict employee attrition** (whether an employee is likely to leave the company) using HR data.  
This analysis helps HR teams identify high-risk employees and design targeted retention strategies.

---

## üßæ Dataset Overview
The dataset contains **1,470 employee records** and **38 features**, including:

| Feature | Description |
|----------|--------------|
| Age | Employee age |
| Department | Functional area (Sales, R&D, HR) |
| JobLevel | Seniority level (1‚Äì5) |
| MonthlyIncome | Salary amount |
| YearsAtCompany | Employee tenure |
| OverTime | Whether employee works overtime (Yes/No) |
| JobSatisfaction, WorkLifeBalance | Categorical satisfaction scores |
| Attrition | Target variable ‚Äî ‚ÄúYes‚Äù (left) / ‚ÄúNo‚Äù (stayed) |

---

## ‚öôÔ∏è Data Preprocessing Steps
1. **Missing Values:** Dataset had no missing records.  
2. **Encoding:**  
   - Used `pd.get_dummies()` for categorical features.  
   - Encoded target (`Attrition`) using `LabelEncoder` (Yes ‚Üí 1, No ‚Üí 0).  
3. **Scaling:**  
   - Applied `StandardScaler` to normalize numeric features.  
4. **Train/Test Split:**  
   - 80 % training / 20 % testing (with stratification).  
5. **Imbalance Handling:**  
   - Used **SMOTE** to oversample minority class and balance attrition = Yes/No.

---

## üß© Model Training
**Algorithm Used:** Random Forest Classifier  

**Why Random Forest?**  
- Handles mixed (categorical + numeric) data well  
- Resistant to overfitting  
- Provides interpretable feature importances

---

## üìä Model Performance

| Metric | Score |
|---------|-------|
| ** Test Accuracy** | 0.86 |
| ** Train Accuracy** | 0.97|
| **Recall adjusted**  | 0.61 |
| **F1 Score** | 0.82|
| **ROC-AUC** | 0.80 |




‚úÖ **Interpretation:**  
The model correctly identifies most employees who will leave while keeping false alarms low.  
ROC-AUC ‚âà 0.88 indicates **strong discrimination ability** between leavers and stayers.

---

## üìà Optimal Decision Threshold
Using the **ROC curve**, the optimal probability threshold was found at:

> üîπ **0.33**

Employees with predicted attrition probability ‚â• 0.40 are classified as **likely to leave**.



---

## üìâ Probability Distribution
This plot shows predicted attrition probabilities for both groups.  
- üüß Orange = Stayed employees (Attrition = No)  
- üîµ Blue = Left employees (Attrition = Yes)  
- üî¥ Dashed line = Decision threshold (0.40)



---

## üßÆ Top 10 Most Influential Features
| Rank | Feature                | Importance |
|------|------------------------|------------|
| 1Ô∏è‚É£  | OverTime_Yes           | 0.145      |
| 2Ô∏è‚É£  | StockOptionLevel       | 0.075      |
| 3Ô∏è‚É£  | JobSatisfaction        | 0.060      |
| 4Ô∏è‚É£  | MaritalStatus_Single   | 0.050      |
| 5Ô∏è‚É£  | YearsAtCompany         | 0.045      |
| 6Ô∏è‚É£  | Age                    | 0.042      |
| 7Ô∏è‚É£  | MonthlyIncome          | 0.040      |
| 8Ô∏è‚É£  | TotalWorkingYears      | 0.038      |
| 9Ô∏è‚É£  | JobInvolvement         | 0.036      |
| üîü   | YearsWithCurrManager   | 0.035      |


üß† **Key Insight:**  
Employees working **overtime**, with **low satisfaction** or **low stock options**, are more prone to leave.

---

## üß© Final Model Interpretation

| Probability Range | Risk Level | HR Action |
|--------------------|-------------|------------|
| 0.00 ‚Äì 0.30 | üü¢ Low Risk | Normal monitoring |
| 0.31 ‚Äì 0.50 | üü° Moderate Risk | Review workload / satisfaction |
| 0.51 ‚Äì 0.70 | üü† High Risk | Engage proactively |
| 0.71 ‚Äì 1.00 | üî¥ Very High Risk | Immediate retention focus |

---

## üí° Key Takeaways
- **OverTime** and **Job Satisfaction** are major attrition drivers.  
- **Younger**, **single**, **low-income** employees are more likely to leave.  
- A **0.40 cutoff** offers the best balance between recall and precision.  
- The model can support **data-driven HR decisions** for employee retention.

---

## üß† Tools & Libraries
`Python ¬∑ pandas ¬∑ numpy ¬∑ matplotlib ¬∑ seaborn ¬∑ scikit-learn ¬∑ imbalanced-learn`

---

## ‚ú® Conclusion
The Random Forest attrition model achieves strong predictive accuracy and interpretability.  
By identifying at-risk employees early, organizations can **reduce turnover**, improve **employee engagement**, and strengthen **HR strategy** through evidence-based analytics.

---

üìç *End of Machine Learning Report*

"""

