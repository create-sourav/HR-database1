# -*- coding: utf-8 -*-
"""HR database EDA and ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rK_m3SQ2o8w4PC1Kqc7NprOoEjubDB5O
"""

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

from google.colab import files
uploaded=files.upload()

df=pd.read_csv("HR database1.csv")
df.head(5)

df.info()
df.isnull().sum().sum()

df.duplicated().sum()

(df["Attrition"]=="Yes").sum()  #238
(df["Attrition"]=="No").sum()  #1233

df["Attrition_rate"]=((df["Attrition"]=="Yes").sum() /len(df["Attrition"])*100)
df["Attrition_rate"]   # Attrition_rate = 16.12%


# df.head(2)

"""### Exploratory Analysis Dashborad"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")
fig, axes = plt.subplots(2, 3, figsize=(16, 10))

# Education vs Attrition (percent within each Education)
sns.countplot(x="Education", hue="Attrition", data=df, stat="percent", ax=axes[0, 0], palette="crest")
axes[0, 0].set_title("Attrition by Education")
axes[0, 0].set_xlabel("Education Level")
axes[0, 0].set_ylabel("Percentage (%)")

# 2) Years Since Last Promotion vs Attrition (percent within each group)
sns.countplot(x="YearsSinceLastPromotion", hue="Attrition", data=df, stat="percent", ax=axes[0, 1], palette="viridis")
axes[0, 1].set_title("Attrition by Years Since Last Promotion")
axes[0, 1].set_xlabel("Years Since Last Promotion")
axes[0, 1].set_ylabel("")

# Job Level vs Attrition (percent)
sns.countplot(x="JobLevel", hue="Attrition", data=df, stat="percent", ax=axes[0, 2], palette="mako")
axes[0, 2].set_title("Attrition by Job Level")
axes[0, 2].set_xlabel("Job Level")
axes[0, 2].set_ylabel("")

# Age distribution by Attrition
sns.histplot(x="Age", hue="Attrition", data=df, bins=15, stat="percent", kde=True, ax=axes[1, 0], palette="viridis")
axes[1, 0].set_title("Age Distribution by Attrition")
axes[1, 0].set_xlabel("Age")
axes[1, 0].set_ylabel("Percentage(%)")

# Department vs Attrition (percent)
sns.countplot(x="Department", hue="Attrition", data=df, stat="percent", ax=axes[1, 1], palette="rocket")
axes[1, 1].set_title("Attrition by Department")
axes[1, 1].set_xlabel("Department")
axes[1, 1].set_ylabel("")
axes[1, 1].tick_params(axis='x', rotation=30)

# Monthly Income distribution by Attrition (histogram)
sns.histplot(x="MonthlyIncome", hue="Attrition", data=df,stat="percent", bins=10, kde=True, ax=axes[1, 2], palette="viridis")
axes[1, 2].set_title("Monthly Income by Attrition")
axes[1, 2].set_xlabel("Monthly Income")
axes[1, 2].set_ylabel("")

plt.tight_layout()
plt.show()

"""# ğŸ“Š Employee Attrition â€” Exploratory Data Analysis (EDA)

## ğŸ§  Objective
The goal of this analysis is to explore factors that contribute to **employee attrition** â€” i.e., employees who leave the company (`Attrition = Yes`).  
We analyze variables like **Education**, **Years Since Last Promotion**, **Job Level**, **Age**, **Department**, and **Monthly Income** to understand key churn drivers.

---

## ğŸ§¾ Dataset Overview

| Feature | Description |
|----------|--------------|
| `Attrition` | Whether an employee left (`Yes`) or stayed (`No`) |
| `Education` | Education level (1 = Below College to 5 = Doctorate) |
| `YearsSinceLastPromotion` | Years since last promotion |
| `JobLevel` | Job seniority (1 â€“ 5) |
| `Age` | Employee age |
| `Department` | Department name |
| `MonthlyIncome` | Monthly salary (USD) |

---

## ğŸ“ˆ Exploratory Insights

### 1ï¸âƒ£ Attrition by Education
- Most employees are at **Education Level 3 (Bachelorâ€™s)**, which also shows the **highest attrition**.  
- Employees with advanced degrees (Masterâ€™s/Doctorate) tend to stay longer.



---

### 2ï¸âƒ£ Attrition by Years Since Last Promotion
- Highest attrition occurs among employees with **0â€“1 years since promotion**, suggesting **career stagnation** drives churn.  
- Attrition decreases with increasing promotion intervals.



---

### 3ï¸âƒ£ Attrition by Job Level
- **Job Levels 1â€“2** have higher attrition rates.  
- **Senior employees (Levels 4â€“5)** show strong retention.



---

### 4ï¸âƒ£ Age Distribution by Attrition
- Younger employees (**25â€“35 years**) have the highest attrition.  
- Older employees (**40+**) tend to remain longer in the organization.



---

### 5ï¸âƒ£ Attrition by Department
- **Research & Development** has the **largest workforce and highest attrition count**.  
- **Sales** also shows notable churn; **HR** remains low.



---

### 6ï¸âƒ£ Attrition by Monthly Income
- Attrition is **highest among low-income employees (< $5,000/month)**.  
- Attrition declines as income increases â€” pay strongly influences retention.



---

## ğŸ§© Key Takeaways
âœ… Younger, low-income, and junior-level employees are more likely to leave.  
âœ… Recent lack of promotions is a major attrition factor.  
âœ… Higher education and senior roles correlate with lower attrition.  
âœ… Retention efforts should target **early-career and low-income** groups.

####  Machine learning predictive analysis
"""

# ---------- FIXED Preprocessing & Modeling Pipeline ----------
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
import pandas as pd

# Define Target and Features
y = df["Attrition"]                # Target column
X = df.drop("Attrition", axis=1)   # Feature columns

# Encode Categorical Variables
X = pd.get_dummies(X, drop_first=True, dtype=int)


# Encode Target Variable (Yes/No -> 1/0)
encoders = {}
if y.dtype == "object" or str(y.dtype).startswith("category"):
    label = LabelEncoder()
    y = label.fit_transform(y.astype(str))
    encoders["Attrition"] = label


# Train-Test Split
x_train, x_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=0
)

# Feature Scaling
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)


# Handle Class Imbalance (SMOTE)
sm = SMOTE(random_state=0)
x_train_resample, y_train_resample = sm.fit_resample(x_train_scaled, y_train)


# Check Class Balance
print("Before SMOTE:\n", pd.Series(y_train).value_counts())
print("\nAfter SMOTE:\n", pd.Series(y_train_resample).value_counts())

print("\nEncoded Target (y):")
print(y)

print("\nEncoded Feature DataFrame (X):")
display(X.head())

"""### Model selection"""

# Models and evaluation (same as your loop)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,
                             recall_score, f1_score, roc_auc_score)

models = {
    "Random Forest": RandomForestClassifier(class_weight="balanced", random_state=0),
    "Logistic Regression": LogisticRegression(random_state=0, max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(random_state=0),
    "naive_bayes": GaussianNB(),
}

for name, model in models.items():
    print("\n===", name, "===")
    model.fit(x_train_resample, y_train_resample)

    y_prediction = model.predict(x_test_scaled)

    acc = accuracy_score(y_test, y_prediction)
    report = classification_report(y_test, y_prediction, zero_division=0)
    confusion = confusion_matrix(y_test, y_prediction)
    recall = recall_score(y_test, y_prediction, average="weighted")
    f1 = f1_score(y_test, y_prediction, average="weighted")

    print("Accuracy:", acc)
    print("Classification Report:\n", report)
    print("Confusion Matrix:\n", confusion)
    print("Recall:", recall)
    print("F1-score:", f1)

# Pretuned RandomForest
RandomForest_model = models["Random Forest"]
RandomForest_model.fit(x_train_resample, y_train_resample)
print("Train accuracy:", RandomForest_model.score(x_train_resample, y_train_resample))
print("Test accuracy:", RandomForest_model.score(x_test_scaled, y_test))

"""### Model tuning"""

RandomForest_tuned = RandomForestClassifier(
    n_estimators=300,
    max_depth=15,
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight="balanced",
    random_state=0
)
RandomForest_tuned.fit(x_train_resample, y_train_resample)

# Print basic train/test accuracy
print("Train accuracy:", RandomForest_tuned.score(x_train_resample, y_train_resample))
print("Test accuracy:", RandomForest_tuned.score(x_test_scaled, y_test))

""" ###  Top 10 Most Important Features Influencing Attrition

"""

importances = pd.Series(RandomForest_tuned.feature_importances_, index=X.columns)
top10 = importances.sort_values(ascending=False).head(10).reset_index()
top10.columns = ["Feature", "Importance"]


# Seaborn barplot
plt.figure(figsize=(10,6))
sns.barplot(
    data=top10,
    y="Feature",
    x="Importance",
    palette="viridis",
    edgecolor="black"
)


# Add chart titles and labels
plt.title(" Top 10 Most Important Features Influencing Attrition", fontsize=14, fontweight="bold", pad=15)
plt.xlabel("Feature Importance Score", fontsize=12)
plt.ylabel("")
plt.grid(axis="x", linestyle="--", alpha=0.4)
sns.despine(left=True, bottom=True)
plt.tight_layout()
plt.show()

"""#### ROC AUC Score"""

from sklearn.metrics import roc_auc_score

y_probability = RandomForest_tuned.predict_proba(x_test_scaled)[:, 1]  # Select probabilities for the positive class
roc_auc = roc_auc_score(y_test, y_probability)
print("ROC AUC:", roc_auc)

def plot_confusion_matrix_with_encoding(model, X_test, y_test, encoder=None, title="Confusion Matrix"):
    """
    Plots a confusion matrix with combined labels (Original Name + Encoded Value).

    Parameters:
        model   : trained sklearn model
        X_test  : processed or scaled test data
        y_test  : true labels (encoded or original)
        encoder : LabelEncoder object used for the target (optional)
        title   : title for the plot
    """

    # ---- Predict and compute confusion matrix ----
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)

    # ---- Build label list ----
    if encoder is not None:
        classes = encoder.classes_
        labels = [f"{cls} ({i})" for i, cls in enumerate(classes)]
    else:
        labels = [str(lbl) for lbl in np.unique(y_test)]

    # ---- Plot ----
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=labels, yticklabels=labels, linewidths=0.5, linecolor='gray')

    plt.title(title, fontsize=14, fontweight='bold', pad=12)
    plt.xlabel("Predicted Label", fontsize=11)
    plt.ylabel("True Label", fontsize=11)
    plt.xticks(rotation=15)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    # ---- Print map as text (for quick reference) ----
    if encoder is not None:
        print("\n Label Encoding Map:\n")
        for i, cls in enumerate(encoder.classes_):
            print(f"{cls:10s} â†’ {i}")

    return cm

"""### Random Forest consusion matrix"""

# Example usage after model training
cm = plot_confusion_matrix_with_encoding(
    model=RandomForest_tuned,
    X_test=x_test_scaled,
    y_test=y_test,
    encoder=encoders["Attrition"],   # LabelEncoder used during preprocessing
    title="Confusion Matrix â€” Random Forest (Encoded Labels)"
)

"""### Optimal Attrition Probability Threshold"""

from sklearn.metrics import roc_curve

# Compute ROC
fpr, tpr, thresholds = roc_curve(y_test, RandomForest_tuned.predict_proba(x_test_scaled)[:, 1])  #False Positive Rate fpr, True Positive Rate tpr

# Find optimal threshold (Youden's J)
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]

print(f"Optimal Attrition Probability Threshold: {optimal_threshold:.3f}")

"""### ROC Curve"""

import matplotlib.pyplot as plt

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, label='ROC Curve')
plt.plot([0,1], [0,1], linestyle='--', color='gray')
plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', label=f'Optimal Threshold = {optimal_threshold:.2f}')
plt.title("ROC Curve â€” Attrition Model")
plt.xlabel("False Positive Rate (1 - Specificity)")
plt.ylabel("True Positive Rate (Sensitivity)")
plt.legend()
plt.show()

"""### Decision Boundary"""

# --- Scale the entire dataset ---
X_scaled = scaler.transform(X)

# --- Predict class and probability ---
y_pred = RandomForest_tuned.predict(X_scaled)

# Extract class names (from LabelEncoder)
classes = encoders["Attrition"].classes_

# Find the index of "Yes" (Attrition = 1)
Attrition_idx = np.where(classes == "Yes")[0][0]

# Get predicted probability for Attrition = "Yes"
attrition_prob = RandomForest_tuned.predict_proba(X_scaled)[:, Attrition_idx]

# --- Add predictions back to DataFrame ---
df["Predicted_Attrition"] = encoders["Attrition"].inverse_transform(y_pred)
df["Attrition_Probability"] = attrition_prob

plt.figure(figsize=(8,5))
sns.kdeplot(data=df, x="Attrition_Probability", hue="Attrition", fill=True, alpha=0.4)
plt.axvline(optimal_threshold, color='red', linestyle='--', linewidth=2)
plt.title("Attrition Probability Distribution by Actual Status", fontsize=12, fontweight='bold')
plt.xlabel("Attrition Probability"); plt.ylabel("Density")

plt.legend(
    ["Attrition = No (Stayed)",
    "Attrition = Yes (Left)",
    f"Threshold = {optimal_threshold:.2f}"
], loc="upper right")

plt.show()

optimal_threshold = 0.395

df["Predicted_Attrition_Adjusted"] = np.where(
    df["Attrition_Probability"] >= optimal_threshold, "Yes", "No"
)

df[["EmployeeNumber", "Attrition", "Predicted_Attrition_Adjusted", "Attrition_Probability"]].head(15)

"""### New Employee Record to predict"""

import pandas as pd

new_employee = pd.DataFrame([{
    "Age": 28,
    "BusinessTravel": "Travel_Rarely",
    "DailyRate": 1100,
    "Department": "Sales",
    "DistanceFromHome": 5,
    "Education": 3,
    "EducationField": "Marketing",
    "EmployeeCount": 1,
    "EmployeeNumber": 9999,              # new employee ID
    "EnvironmentSatisfaction": 3,
    "Gender": "Male",
    "HourlyRate": 70,
    "JobInvolvement": 3,
    "JobLevel": 2,
    "JobRole": "Sales Executive",
    "JobSatisfaction": 3,
    "MaritalStatus": "Single",
    "MonthlyIncome": 4500,
    "MonthlyRate": 15000,
    "NumCompaniesWorked": 2,
    "Over18": "Y",
    "OverTime": "Yes",                  # this employee works overtime
    "PercentSalaryHike": 13,
    "PerformanceRating": 3,
    "RelationshipSatisfaction": 3,
    "StandardHours": 80,
    "StockOptionLevel": 1,
    "TotalWorkingYears": 6,
    "TrainingTimesLastYear": 3,
    "WorkLifeBalance": 2,
    "YearsAtCompany": 3,
    "YearsInCurrentRole": 2,
    "YearsSinceLastPromotion": 1,
    "YearsWithCurrManager": 2
}])

"""### Match Columns to the Modelâ€™s Input"""

# Drop Attrition (since we are predicting it)
X_new = new_employee.copy()

# Encode categorical columns like before
X_new = pd.get_dummies(X_new, drop_first=True)

# Align with training columns (to ensure same shape)
X_new = X_new.reindex(columns=X.columns, fill_value=0)

# Scale numeric features
X_new_scaled = scaler.transform(X_new)

"""### Prediction Using the Model"""

# Predict class
y_pred_new = RandomForest_tuned.predict(X_new_scaled)

# Predict probability of attrition (Yes)
labeler = encoders["Attrition"]
prob_yes = RandomForest_tuned.predict_proba(X_new_scaled)[:, np.where(labeler.classes_ == "Yes")[0][0]]

# Decode predicted class
predicted_label = labeler.inverse_transform(y_pred_new)[0]
predicted_probability = prob_yes[0]

print(f"Predicted Attrition: {predicted_label}")
print(f"Attrition Probability: {predicted_probability:.2%}")

"""# ğŸ¤– Employee Attrition Prediction â€” Machine Learning Report

## ğŸ§  Project Objective
The goal of this machine learning project is to **predict employee attrition** (whether an employee is likely to leave the company) using HR data.  
This analysis helps HR teams identify high-risk employees and design targeted retention strategies.

---

## ğŸ§¾ Dataset Overview
The dataset contains **1,470 employee records** and **38 features**, including:

| Feature | Description |
|----------|--------------|
| Age | Employee age |
| Department | Functional area (Sales, R&D, HR) |
| JobLevel | Seniority level (1â€“5) |
| MonthlyIncome | Salary amount |
| YearsAtCompany | Employee tenure |
| OverTime | Whether employee works overtime (Yes/No) |
| JobSatisfaction, WorkLifeBalance | Categorical satisfaction scores |
| Attrition | Target variable â€” â€œYesâ€ (left) / â€œNoâ€ (stayed) |

---

## âš™ï¸ Data Preprocessing Steps
1. **Missing Values:** Dataset had no missing records.  
2. **Encoding:**  
   - Used `pd.get_dummies()` for categorical features.  
   - Encoded target (`Attrition`) using `LabelEncoder` (Yes â†’ 1, No â†’ 0).  
3. **Scaling:**  
   - Applied `StandardScaler` to normalize numeric features.  
4. **Train/Test Split:**  
   - 80 % training / 20 % testing (with stratification).  
5. **Imbalance Handling:**  
   - Used **SMOTE** to oversample minority class and balance attrition = Yes/No.

---

## ğŸ§© Model Training
**Algorithm Used:** Random Forest Classifier  

**Why Random Forest?**  
- Handles mixed (categorical + numeric) data well  
- Resistant to overfitting  
- Provides interpretable feature importances

---

## ğŸ“Š Model Performance

| Metric | Score |
|---------|-------|
| **Accuracy** | ~ 0.85 |
| **Precision (Attrition = Yes)** | ~ 0.79 |
| **Recall (Attrition = Yes)** | ~ 0.73 |
| **F1 Score (Attrition = Yes)** | ~ 0.76 |
| **ROC-AUC** | ~ 0.88 |

âœ… **Interpretation:**  
The model correctly identifies most employees who will leave while keeping false alarms low.  
ROC-AUC â‰ˆ 0.88 indicates **strong discrimination ability** between leavers and stayers.

---

## ğŸ“ˆ Optimal Decision Threshold
Using the **ROC curve**, the optimal probability threshold was found at:

> ğŸ”¹ **0.395 (â‰ˆ 0.40)**

Employees with predicted attrition probability â‰¥ 0.40 are classified as **likely to leave**.



---

## ğŸ“‰ Probability Distribution
This plot shows predicted attrition probabilities for both groups.  
- ğŸŸ§ Orange = Stayed employees (Attrition = No)  
- ğŸ”µ Blue = Left employees (Attrition = Yes)  
- ğŸ”´ Dashed line = Decision threshold (0.40)



---

## ğŸ§® Top 10 Most Influential Features

| Rank | Feature | Importance |
|------|----------|-------------|
| 1ï¸âƒ£ | OverTime _Yes | 0.145 |
| 2ï¸âƒ£ | StockOptionLevel | 0.070 |
| 3ï¸âƒ£ | JobSatisfaction | 0.061 |
| 4ï¸âƒ£ | JobLevel | 0.039 |
| 5ï¸âƒ£ | MaritalStatus_Single | 0.038 |
| 6ï¸âƒ£ | EnvironmentSatisfaction | 0.037 |
| 7ï¸âƒ£ | Age | 0.037 |
| 8ï¸âƒ£ | MonthlyIncome | 0.035 |
| 9ï¸âƒ£ | YearsAtCompany | 0.034 |
| ğŸ”Ÿ | TotalWorkingYears | 0.033 |

ğŸ§  **Key Insight:**  
Employees working **overtime**, with **low satisfaction** or **low stock options**, are more prone to leave.

---

## ğŸ§© Final Model Interpretation

| Probability Range | Risk Level | HR Action |
|--------------------|-------------|------------|
| 0.00 â€“ 0.30 | ğŸŸ¢ Low Risk | Normal monitoring |
| 0.31 â€“ 0.50 | ğŸŸ¡ Moderate Risk | Review workload / satisfaction |
| 0.51 â€“ 0.70 | ğŸŸ  High Risk | Engage proactively |
| 0.71 â€“ 1.00 | ğŸ”´ Very High Risk | Immediate retention focus |

---

## ğŸ’¡ Key Takeaways
- **OverTime** and **Job Satisfaction** are major attrition drivers.  
- **Younger**, **single**, **low-income** employees are more likely to leave.  
- A **0.40 cutoff** offers the best balance between recall and precision.  
- The model can support **data-driven HR decisions** for employee retention.

---

## ğŸ§  Tools & Libraries
`Python Â· pandas Â· numpy Â· matplotlib Â· seaborn Â· scikit-learn Â· imbalanced-learn`

---

## âœ¨ Conclusion
The Random Forest attrition model achieves strong predictive accuracy and interpretability.  
By identifying at-risk employees early, organizations can **reduce turnover**, improve **employee engagement**, and strengthen **HR strategy** through evidence-based analytics.

---

ğŸ“ *End of Machine Learning Report*

"""

